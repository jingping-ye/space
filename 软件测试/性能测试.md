## 一、性能测试基础

对于不同类型的系统，软件性能的关注点各不相同，比如：Web 类应用和手机端应用，一般以终端用户感受到的端到端的响应时间来描述系统的性能；非交互式的应用，比如典型的电信和银行后台处理系统，响应时间关注更多的是事件处理的速度，以及单位时间的事件吞吐量。

对软件性能关注的期望群体：终端用户、系统运维人员、软件设计开发人员、性能测试人员。

### （一）终端用户的软件性能

- 系统响应时间，反应的是系统能力，又可以进一步细分为应用系统处理时间、数据库处理时间和网络传输时间等；
- 前端展现时间，取决于用户端的处理能力。

### （二）系统运维人员的软件性能

- 单个用户的响应时间
- 大量用户并发访问时的负载
- 更大负载情况下的系统健康状态
- 并发处理能力
- 当前部署的系统容量
- 可能的系统瓶颈
- 系统配置层面的调优
- 数据库的调优
- 长时间运行稳定性和可拓展性

#### 运维人员与终端用户的区别

当有两套系统配置方案可以提供以下系统能力的时：配置方案 A 可以提供 100 万并发访问用户的能力，此时用户的登录响应时间是 3 秒；配置方案 B 可以提供 500 万并发访问用户的能力，此时用户的登录响应时间是 8 秒。这时，从全局利益最大化角度来看，系统具有更大并发用户承载能力的价值会更大，所以运维人员一般都会选择方案 B。目前，有些系统为了能够承载更多的并发用户，往往会牺牲等待时间而引入预期的等待机制。比如，火车票购票网站，就在处理极大并发用户时采用了排队机制，以尽可能提高系统容量，但却增加了用户实际感受到的响应时间。

### （三）软件设计开发人员的软件性能

- 算法设计
  - 核心算法的设计与实现是否高效；
  - 必要时，设计上是否采用 buffer 机制以提高性能，降低 I/O；
  - 是否存在潜在的内存泄露；
  - 是否存在并发环境下的线程安全问题；
  - 是否存在不合理的线程同步方式；
  - 是否存在不合理的资源竞争。
- 架构核心
  - 站在整体系统的角度，是否可以方便地进行系统容量和性能扩展；
  - 应用集群的可扩展性是否经过测试和验证；
  - 缓存集群的可扩展性是否经过测试和验证；
  - 数据库的可扩展性是否经过测试和验证。
- 性能最佳实践
  - 代码实现是否遵守开发语言的性能最佳实践；
  - 关键代码是否在白盒级别进行性能测试；
  - 是否考虑前端性能的优化；
  - 必要的时候是否采用数据压缩传输；
  - 对于既要压缩又要加密的场景，是否采用先压缩后加密的顺序。
- 数据库相关
  - 数据库表设计是否高效；是否引入必要的索引；
  - SQL 语句的执行计划是否合理；
  - SQL 语句除了功能是否要考虑性能要求；
  - 数据库是否需要引入读写分离机制；
  - 系统冷启动后，缓存大量不命中的时候，数据库承载的压力是否超负荷。
- 软件性能的可测试性
  - 是否为性能分析（Profiler）提供必要的接口支持；
  - 是否支持高并发场景下的性能打点；
  - 是否支持全链路的性能分析。

### （四）性能工程师眼中的性能测试

> 好的性能工程师就是一位医生

性能测试工程师关注的是算法设计、架构设计、性能最佳实践、数据库相关、软件性能的可测试性这五大方面。

一个优秀的性能测试工程师，一般需要具有以下技能：

- 性能需求的总结和抽象能力；
- 根据性能测试目标，精准的性能测试场景设计和计算能力；
- 性能测试场景和性能测试脚本的开发和执行能力；
- 测试性能报告的分析解读能力；
- 性能瓶颈的快速排查和定位能力；
- 性能测试数据的设计和实现能力；
- 面对互联网产品，全链路压测的设计与执行能力，能够和系统架构师一起处理流量标记、影子数据库等的技术设计能力；
- 深入理解性能测试工具的内部实现原理，当性能测试工具有限制时，可以进行扩展二次开发；
- 极其宽广的知识面，既要有“面”的知识，比如系统架构、存储架构、网络架构等全局的知识，还要有大量“点”的知识积累，比如数据库 SQL 语句的执行计划调优、JVM 垃圾回收（GC）机制、多线程常见问题等等。

### （五）衡量软件性能的常用指标

> 并发用户数、响应时间、系统吞吐量

1. 并发用户数

- 业务层面的并发用户数，指的是实际使用系统的用户总数。但是，单靠这个指标并不能反映系统实际承载的压力，我们还要结合用户行为模型才能得到系统实际承载的压力。

- 后端服务器层面的并发用户数，指的是“同时向服务器发送请求的数量”，直接反映了系统实际承载的压力。

  > 如果一个系统有5000人使用，经过日志分析，该系统最大用户是2500人。那么这个2500人就是业务层面的并发用户数。在同一时间点上，这2500个用户，有30%在页面浏览状态,20%的用户在填写订单，5%提交订单,15%用户在查询订单，另外30%的用户无任何操作，那么真正对服务器产生压力的只有5%的提交订单用户和15%的查询订单用户，那么此时的并发用户数为20%*2500=500人。

分析得到准确的用户行为模式，是性能测试中关键一环。

目前，获取用户行为模式的方法，主要分为两种：对于已经上线的系统来说，往往采用系统日志分析法获取用户行为统计和峰值并发量等重要信息；而对于未上线的全新系统来说，通常的做法是参考行业中类似系统的统计信息来建模，然后分析。

2. 响应时间

   >  响应时间反映了完成某个操作所需要的时间，其标准定义是“应用系统从请求发出开始，到客户端接收到最后一个字节数据所消耗的时间”，是用户视角软件性能的主要体现。

响应时间，分为前端展现时间和系统响应时间两部分。

- 前端时间，又称呈现时间，取决于客户端收到服务器返回的数据后渲染页面所消耗的时间；
- 系统响应时间，又可以进一步划分为 Web 服务器时间、应用服务器时间、数据库时间，以及各服务器间通信的网络时间。

3. 系统吞吐量

> 系统吞吐量体现软件系统承受负载能力的指标。Throughput”翻译成吞吐率更贴切，因为我们可以这样理解：吞吐率 = 吞吐量 / 单位时间

性能测试： Requets/second pages/second bytes/second

业务角度:单位时间的业务处理数量

- “Bytes（发送的字节数）/Second（网卡每秒接收）”和“Pages/Second”表示的吞吐量，主要受网络设置、服务器架构、应用服务器制约；
- “Requests/Second”表示的吞吐量，主要受应用服务器和应用本身实现的制约。（HTTP）

比如，某个测试场景中采用 100 个并发用户，每个用户每隔 1 秒发出一个 Request，另外一个测试场景采用 1000 个并发用户，每个用户每隔 10 秒发出一个 Request。显然这两个场景具有相同的吞吐量, 都是 100 Requests/second，但是两种场景下的系统性能拐点肯定不同。因为，两个场景所占用的资源是不同的。

## 二、性能测试基本方法和应用领域

### （一）并发用户数、响应时间、系统吞吐量之间的关系

把整个体检中心想象成一个软件系统，从你进入体检中心到完成全部检查离开所花费的时间就是响应时间，而同时在体检中心参加体检的总人数就是并发用户数，那么系统吞吐量就可以想象成是单位时间内完成体检的人数，比如每小时 100 人。如果你到达体检中心的时间比较早，这时人还很少，5 个科室都不用排队，那么你就能以最短的时间完成体检。如果你到达体检中心时，这里的人已经比较多了，只有部分科室不需要排队，但好在每个科室都有 3 个候诊室同时进行检查，所以排队时间不会很长，你还是可以在较短的时间完成体检。但是，当体检中心的人越来越多时，每个科室都需要排队，而且每个科室的队伍都很长，你每检查完一个项目都要花很长时间去排队进行下一个检查项目。这样一来，你完成体检的时间就会明显变长。最糟糕的情况来了，如果体检中心的人继续增加，你会发现连排队、站人的地方都没有了，所有人都被堵在了一起，候诊室中检查完的人出不来，排队的人又进不去。

1. 也就是说，当系统的并发用户数比较少时，响应时间就比较短；但是由于整体的并发用户数少，所以系统的吞吐量也很低。从中，我们可以得出这样的结论：当系统并发用户数较少时，系统的吞吐量也低，系统处于空闲状态，我们往往把这个阶段称为 “空闲区间”。
2. 就是说，当系统的并发用户数比较多时，响应时间不会增加太多，因此系统的整体吞吐量也随着并发用户数的变大而变大的。从中，我们可以得出这样的结论：当系统整体负载并不是很大时，随着系统并发用户数的增长，系统的吞吐量也会随之呈线性增长，我们往往把这个阶段称为 “线性增长区间”。
3. 也就是说，系统的并发用户数达到一定规模时，每个用户的响应时间都会明显变长，所以系统的整体吞吐量并不会继续随着并发用户数的增长而增长。从中，我们可以得出这样的结论：随着系统并发用户数的进一步增长，系统的处理能力逐渐趋于饱和，因此每个用户的响应时间会逐渐变长。相应地，系统的整体吞吐量并不会随着并发用户数的增长而继续呈线性增长。我们往往把这个阶段称为系统的“拐点”。
4. 也就是说，系统的并发用户数已经突破极限，每个用户的响应时间变得无限长，因此系统的整体吞吐量变成了零。换言之，此时的系统已经被压垮了。从中，我们可以得出这样的结论：随着系统并发用户数的增长，系统处理能力达到过饱和状态。此时，如果继续增加并发用户数，最终所有用户的响应时间会变得无限长。相应地，系统的整体吞吐量会降为零，系统处于被压垮的状态。我们往往把这个阶段称为“过饱和区间”。

比如，后端性能测试的测试负载，我们一般只会把它设计在“线性增长区间”内；而压力测试的测试负载，我们则会将它设计在系统“拐点”上下，甚至是“过饱和区间”。

### （二）性能测试方法

1. 后端性能测试（Back-end Performance Test）

> 后端性能测试，是通过性能测试工具模拟大量的并发用户请求，然后获取系统性能的各项指标，并且验证各项指标是否符合预期的性能需求的测试手段。

性能指标:

- 并发用户数
- 响应时间
- 系统吞吐量
- 各类资源的使用率
  - 系统级别的CPU占用率
  - 内存使用率
  - 磁盘I/O
  - 网络I/O
  - 应用级别
  - JVM级别的各类资源使用率指标

根据应用领域的不同，后端性能测试的场景设计主要包括以下两种方式：

- 基于性能需求目标的测试验证；
- 探索系统的容量，并验证系统容量的可扩展性

2. 前端性能测试(Front-end Performance Test)

> 前端性能关注的是浏览器端的页面渲染时间、资源加载顺序、请求数量、前端缓存使用情况、资源压缩等内容，希望借此找到页面加载过程中比较耗时的操作和资源，然后进行有针对性的优化，最终达到优化终端用户在浏览器端使用体验的目的。

[雅虎前端优化](https://developer.yahoo.com/performance/rules.html?guccounter=1)

- 减少 http 请求次数：http 请求数量越多，执行过程耗时就越长，所以可以采用合并多个图片到一个图片文件的方法来减少 http 请求次数，也可以采用将多个脚本文件合并成单一文件的方式减少 http 请求次数；
- 减少 DNS 查询次数：DNS 的作用是将 URL 转化为实际服务器主机 IP 地址，实现原理是分级查找，查找过程需要花费 20~100ms 的时间，所以一方面我们要加快单次查找的时间，另一方面也要减少一个页面中资源使用了多个不同域的情况；
- 避免页面跳转：页面跳转相当于又打开一个新的页面，耗费的时间就会比较长，所以要尽量避免使用页面跳转；
- 使用内容分发网络（CDN）：使用 CDN 相当于对静态内容做了缓存，并把缓存内容放在网络供应商（ISP）的机房，用户根据就近原则到 ISP 机房获取这些被缓存了的静态资源，因此可以大幅提高性能；
- Gzip 压缩传输文件：压缩可以帮助减小传输文件的大小，进而可以从网络传输时间的层面来减少响应时间；

3. 代码性能测试(Code-level Performance Test)

> 代码级性能测试，是指在单元测试阶段就对代码的时间性能和空间性能进行必要的测试和评估，以防止底层代码的效率问题在项目后期才被发现的尴尬。

实际执行的层面来讲，代码级性能测试并不存在严格意义上的测试工具，通常的做法是：改造现有的单元测试框架。

最常使用的改造方法是：

 - 将原本只会执行一次的单元测试用例连续执行 n 次，这个 n 的取值范围通常是 2000~5000；

 - 统计执行 n 次的平均时间。如果这个平均时间比较长（也就是单次函数调用时间比较长）的话，比如已经达到了秒级，那么通常情况下这个被测函数的实现逻辑一定需要优化。

   这里之所以采用执行 n 次的方式，是因为函数执行时间往往是毫秒级的，单次执行的误差会比较大，所以采用多次执行取平均值的做法。

4. 压力测试(Load/Stress Test)

> 压力测试，通常指的是后端压力测试，一般采用后端性能测试的方法，不断对系统施加压力，并验证系统化处于或长期处于临界饱和阶段的稳定性以及性能指标，并试图找到系统处于临界状态时的主要瓶颈点。所以，压力测试往往被用于系统容量规划的测试。还有些情况，在执行压力测试时，我们还会故意在临界饱和状态的基础上继续施加压力，直至系统完全瘫痪，观察这个期间系统的行为；然后，逐渐减小压力，观察瘫痪的系统是否可以自愈。

5. 配置测试（Configuration Test）

> 配置测试，主要用于观察系统在不同配置下的性能表现。配置包括宿主操作系统的配置、应用服务器的配置、数据库的配置、JVM 的配置、网络环境的配置

通常使用后端性能测试的方法：

1. 通过性能基准测试（Performance Benchmark）建立性能基线（Performance Baseline）；
2. 在此基础上，调整配置；
3. 基于同样的性能基准测试，观察不同配置条件下系统性能的差异，根本目的是要找到特定压力模式下的最佳配置。

6. 并发测试(Concurrence Test)

> 并发测试，指的是在同一时间，同时调用后端服务，期间观察被调用服务在并发情况下的行为表现，旨在发现诸如资源竞争、资源死锁之类的问题。

集合点并发

比如，当要求的集合点并发数是 100 时，那么前 99 个到达的用户都会等在那里，直到第 100 个用户到了，才集中向后端服务发起请求。当然，实际达到服务器的并发请求数，还会因为网络延迟等原因小于 100。

7. 可靠性测试(Reliability Test)

> 可靠性测试，是验证系统在常规负载模式下长期运行的稳定性,但其本质就是通过长时间模拟真实的系统负载来发现系统潜在的内存泄漏、链接池回收等问题。

由于真实环境下的实际负载，会有高峰和低谷的交替变化（比如，对于企业级应用，白天通常是高峰时段，而晚上则是低峰时段），所以为了尽可能地模拟出真实的负载情况，我们会每 12 小时模拟一个高峰负载，两个高峰负载中间会模拟一个低峰负载，依次循环 3-7 天，形成一个类似于“波浪形”的系统测试负载曲线。然后，用这个“波浪形”的测试负载模拟真实的系统负载，完成可靠性测试。同样地，可靠性测试也会持续 3-7 天。

### （三）性能测试应用领域

1. 能力验证

> 能力验证是最常用，也是最容易理解的性能测试的应用领域，主要是验证“某系统能否在 A 条件下具有 B 能力”，通常要求在明确的软硬件环境下，根据明确的系统性能需求设计测试方案和用例。

能力验证这个领域最常使用的测试方法，包括后端性能测试、压力测试和可靠性测试。

2. 能力规划

> 能力规划关注的是，如何才能使系统达到要求的性能和容量。通常情况下，我们会采用探索性测试的方式来了解系统的能力。

能力规划解决的问题，主要包括以下几个方面：

- 能否支持未来一段时间内的用户增长；

- 应该如何调整系统配置，使系统能够满足不断增长的用户数需求；

- 应用集群的可扩展性验证，以及寻找集群扩展的瓶颈点；

- 数据库集群的可扩展性验证；

- 缓存集群的可扩展性验证；

- …

  能力规划最常使用的测试方法，主要有后端性能测试、压力测试、配置测试和可靠性测试。

3. 性能调优

> 性能调优主要解决性能测试过程中发现的性能瓶颈的问题，通常会涉及多个层面的调整，包括硬件设备选型、操作系统配置、应用系统配置、数据库配置和应用代码实现的优化等等。

这个领域最常用的测试方法，涵盖了我在上面分享的七大类测试方法，即后端性能测试、前端性能测试、代码级性能测试、压力测试、配置测试、并发测试和可靠性测试。

4. 缺陷发现

>  缺陷发现，是一个比较直接的应用领域，通过性能测试的各种方法来发现诸如内存泄露、资源竞争、不合理的线程锁和死锁等问题。

缺陷发现，最常用的测试方法主要有并发测试、压力测试、后端性能测试和代码级性能测试。

## 三、后端性能测试工具

> 完整的后端性能测试应该包括性能需求获取、性能场景设计、性能测试脚本开发、性能场景实现、性能测试执行、性能结果报告分析、性能优化和再验证。

看病案例：需求获取对应的是你向医生描述身体不适细节的过程，医生需要知道要帮你解决什么问题；设计性能场景对应的是医生决定需要检查哪些血液指标的过程；使用性能测试工具对应的是使用医疗仪器分析血样的过程 ;性能测试报告对应的就是验血报告 ;性能测试人员分析性能结果报告的过程，对应的是医生解读验血报告的过程；性能测试人员根据性能报告进行性能优化的过程，对应的是医生根据验血报告判断你的病情，并给出相应治疗措施的过程。

后端性能测试：本质是通过协议模拟用户的行为。开发完成了虚拟用户脚本之后，后端性能测试工具会以多线程或多进程的方式并发执行虚拟用户脚本，来模拟大量并发用户的同时访问，从而对服务器施加测试负载。

我们把实际发起测试负载的机器称为压力产生器。受限于 CPU、内存，以及网络带宽等硬件资源，一台压力产生器能够承载的虚拟用户数量是有限的，当需要发起的并发用户数量超过了单台压力产生器能够提供的极限时，就需要引入多台压力产生器合作发起需要的测试负载。

一旦有了多台压力产生器，那就需要一个专门的控制器来统一管理与协调这些压力产生器，我们把这个专门的控制器称为压力控制器。压力控制器会根据性能测试场景的设计，来控制和协调多台压力产生器上的多线程或多进程执行的虚拟用户脚本，最终模拟出性能测试场景中的测试负载。

接着，在施加测试负载的整个过程中，后端性能测试工具除了需要监控和收集被测系统的各种性能数据以外，还需要监控被测系统各个服务器的各种软硬件资源。比如，后端性能测试工具需要监控应用服务器、数据库服务器、消息队列服务器、缓存服务器等各种资源的占用率。我们通常把完成监控和数据收集的模块称为系统监控器。

最后，测试执行完成后，后端性能测试工具会将系统监控器收集的所有信息汇总为完整测试报告，后端性能测试工具通常能够基于该报告生成各类指标的各种图表，还能将多个指标关联在一起进行综合分析来找出各个指标之间的关联性。我们把完成这部分工作的模块称为测试结果分析器。

（一）后端性能测试场景设计

- 并发用户数是多少？
- 测试刚开始时，以什么样的速率来添加并发用户？比如，每秒增加 5 个并发用户。
- 达到最大并发用户数后持续多长时间？
- 测试结束时，以什么样的速率来减少并发用户？比如，每秒减少 5 个并发用户。
- 需要包含哪些业务操作，各个业务操作的占比是多少？比如，10% 的用户在做登录操作，70% 的用户在做查询操作，其他 20% 的用户在做订单操作。
- 一轮虚拟用户脚本执行结束后，需要等待多长时间开始下一次执行？
- 同一虚拟用户脚本中，各个操作之间的等待时间是多少？
- 需要监控哪些被测服务器的哪些指标？
- 脚本出错时的处理方式是什么？比如，错误率达到 10% 时，自动停止该脚本。
- 需要使用多少台压力产生器？

### （二）性能测试工具

- LoadRunner（按照用户并发数收费）
- JMeter（开源免费,可支持千万级至亿级的海量并发）
- NeoLoad
- CloudTest
- Loadstorm
- 阿里的PT
- locust
- gatling

## 四、前端性能测试工具

- WebPagetest
- puppteer

### （一）指标

1. First Byte Time

> 指的是用户发起页面请求到接收到服务器返回的第一个字节所花费的时间。这个指标反映了后端服务器处理请求、构建页面，并且通过网络返回所花费的时间

2. Keep-alive Enabled

> 页面上的各种资源（比如，图片、JavaScript、CSS 等）都需要通过链接 Web 服务器来一一获取，与服务器建立新链接的过程往往比较耗费时间，所以理想的做法是尽可能重用已经建立好的链接，而避免每次使用都去创建新的链接。Keep-alive Enabled 就是，要求每次请求使用已经建立好的链接。它属于服务器上的配置，不需要对页面本身进行任何更改，启用了 Keep-alive 通常可以将加载页面的时间减少 40%~50％，页面的请求数越多，能够节省的时间就越多。

3. Compress Transfer

> 如果将页面上的各种文本类的资源，比如 Html、JavaScript、CSS 等，进行压缩传输，将会减少网络传输的数据量，同时由于 JavaScript 和 CSS 都是页面上最先被加载的部分，所以减小这部分的数据量会加快页面的加载速度，同时也能缩短 First Byte Time。为文本资源启用压缩通常也是服务器配置更改，无需对页面本身进行任何更改

4. Compress Images

> 为了减少需要网络传输的数据量，图像文件也需要进行压缩处理。显然本次测试结果显示（图 5），所有的 JPEG 格式图片都没有经过必要的压缩处理，并且所有的 JPEG 格式图片都没有使用渐进式 JPEG（Progressive JPEG）技术，所以 WebPagetest 给出了 D 级的评分。通 JPEG 文件存储方式是按从上到下的扫描方式，把每一行顺序地保存在 JPEG 文件中。打开这个文件显示它的内容时，数据将按照存储时的顺序从上到下一行一行地被显示，直到所有的数据都被读完，就完成了整张图片的显示。如果文件较大或者网络下载速度较慢，就会看到图片是被一行一行加载的。为了更好的用户体验，渐进式 JPEG 技术就出现了。渐进式 JPEG 包含多次扫描，然后将扫描顺序存储在 JPEG 文件中。打开文件的过程，会先显示整个图片的模糊轮廓，随着扫描次数的增加，图片会变得越来越清晰。这种格式的主要优点是在网络较慢时，通过图片轮廓就可以知道正在加载的图片大概是什么。

5. Cache Static Content

> 一般情况下，页面上的静态资源不会经常变化，所以如果你的浏览器可以缓存这些资源，那么当重复访问这些页面时，就可以从缓存中直接使用已有的副本，而不需要每次向 Web 服务器请求资源。这种做法，可以显著提高重复访问页面的性能，并减少 Web 服务器的负载。

6. Effective use of CDN

>  CDN 是内容分发网络的缩写，其基本原理是采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区的网络供应商机房内，当用户访问网站时，利用全局负载技术将用户的访问指向距离最近的、工作正常的缓存服务器上，由缓存服务器直接响应用户请求。

7. Start Render

> Start Render，指的是浏览器开始渲染的时间，从用户角度看就是在页面上看到第一个内容的时间。该时间决定了用户对页面加载快慢的的第一直观印象，这个时间越短用户会感觉页面速度越快，这样用户也会有耐心去等待其他内容的展现。如果这个时间过长，则用户会在长时间内面对一个空白页面后，失去耐心。

理想的 Start Render 时间并没有严格的标准，一般来情况下，这个值最好不要大于 3 s

8.First Interactive

> First Interactive，可以简单地理解为最早的页面可交互时间。页面中可交互的内容，包括很多种类，比如点击一个链接、点击一个按钮都属于页面可交互的范畴。First Interactive 时间的长短对用户体验的影响十分重要，决定着用户对页面功能的使用，这个值越短越好。为了使这个值尽可能得小，我们通常会采取以下措施：只有页面控件内容渲染出来了，才有可能进行交互，所以 First Interactive 依赖于 Start Render 时间。尽量将交互控件的代码放置在 HTML BODY 的前部，让其尽早加载。尽早做 JavaScript 的初始化和绑定，目前大多数做法有两种，一是在 DOM Ready 中做所有 JavaScript 的初始化和功能绑定，二是在页面底部做 JavaScript 的初始化和功能绑定。

9. Speed Index

> Speed Index 是通过微积分定义的。我们理解起来会比较困难，所以在这里我们和你只做定性的讨论。通常，影响网页性能体验的一个重要指标是页面打开时间。打开时间越短，其体验越好。但是，当存在两个打开时间完全相同的网站 A 和 B 时，其中网站 A 的打开过程是逐渐渲染页面完成的，而网站 B 的打开过程则是空白了一段时间后在短时间内完成页面渲染完成的。毫无疑问，网站 A 的用户体验一定好于 B。Speed Index 就是用来衡量这种体验的，通常来讲，它的值越小越好。

WebPagetest API Wrapper 是一款基于 Node.js，调用了 WebPagetest 提供的 API 的命令行工具。也就是说，你可以利用这个命令行工具发起基于 WebPagetest 的前端性能测试，这样就可以很方便地与 CI/CD 流水线集成了。





## （其他）全链路压测

> 全链路压测，是基于真实的生产环境来模拟海量的并发用户请求和数据，对整个业务链路进行压力测试，试图找到所有潜在性能瓶颈点并持续优化的实践。全链路压测的应用场景，不仅仅包括验证系统在峰值期间的稳定性，还会包含新系统上线后的性能瓶颈定位以及站点容量的精准规划。

由于某些业务模块的操作负载会集中到几个最核心的组件上，那么通过全链路压测的模拟，我们就能快速识别出哪些模块的负载过大，哪些模块的负载偏小。这样我们在对系统进行扩容时，就可以把资源更多地给到那些承受大负载的模块，而那些承受负载偏小的模块就可以进行适当的收缩来让出更多的可用资源。这，就是精准的容量规划。

### 单系统的独立压测

压测主要是通过模拟单一系统的海量并发请求来实现的。而模拟海量请求主要有两种实现方式：

- 一种是，根据设计的压力来直接模拟大量的并发调用；
- 另一种是，先获取线上真实的流量请求，然后经过数据清洗后，再回放模拟大量的并发调用。

- 单系统压测的时候，会假设其依赖的所有系统能力都是无限的，而实际情况一定不是这样，这就造成了单系统压测的数据普遍比较乐观的情况；
- 在大压力环境下，各系统间的相互调用会成为系统瓶颈，但这在单系统压测的时候根本无法体现；
- 大压力环境下，各系统还会出现抢占系统资源（比如网络带宽、文件句柄）的情况，这种资源抢占必然会引入性能问题，但是这类问题在单系统压测过程中也无法体现出来；
- 由于是单系统测试，所以通常都只会先选择最核心的系统来测试，这就意味着其他的非核心系统会被忽略，而在实际项目中，这些非核心系统也很有可能会造成性能瓶颈。

### 全链路压测

> 全链路压测会把整个系统看作一个整体，然后在真实的生产环境上尽可能真实地去模拟业务的海量并发操作，以此来衡量系统的实际承载能力，或者找出系统可能的瓶颈点并给出相应的解决方案。

#### 全链路压测的技术难点

1. 海量并发请求的发起；
2. 全链路压测流量的隔离；
3. 实际业务负载的模拟；
4. 测试完成后的数据清理。

#### 使用JMeter进行压力测试

1. 虽然采用了分布式的 JMeter 方案，并发数量也会存在上限，比如面对亿级的海量并发时，主要原因是分布式的 JMeter 方案中，Master 节点会成为整个压测发起的瓶颈。为了解决这个难题，很多公司并不会直接采用分布式 JMeter 架构来完成海量并发，而是会使用 Jenkins Job 单独调用 JMeter 节点来控制和发起测试压力。这样就避免了 Master 节点引发的瓶颈问题。而且，由于各个 JMeter 是完全独立的，所以只要 Jenkins Job 足够多，并且网络带宽不会成为瓶颈的情况下，就能发起足够大的并发。
2. 测试脚本、测试数据和测试结果在分布式 JMeter 环境中的分发难题。如果直接采用分布式的 JMeter 方案，测试脚本需要通过 JMeter 的 Master 节点来分发，测试数据文件则要用户自行上传至每套虚拟机，同时测试结果还要通过 JMeter 的 Slave 节点回传至 Master 节点。所以，更好的做法是基于 JMeter 来搭建一个压测框架，诸如脚本分发、数据分发以及结果回传等工作，都由压测框架完成。这也是目前绝大多数大型互联网企业的做法。比如，饿了么就采用这种方式搭建了压测平台，并且取得了很好的效果。
3. 流量发起的地域要求。全链路压测流量的发起很多时候是有地理位置要求的，比如 30% 的压力负载来自上海、30% 的压力负载来自北京等，这就要求我们在多个城市的数据中心都搭建 JMeter Slave，以便可以发起来自多个地域的组合流量。

## LoaderRunner

### 后端性能测试工具

后端性能测试工具首先通过虚拟用户脚本生成器生成基于协议的虚拟用户脚本，然后根据性能测试场景设计的要求，通过压力控制器控制协调各个压力产生器以并发的方式执行虚拟用户脚本，并且在测试执行过程中，通过系统监控器收集各种性能指标以及系统资源占用率，最后通过测试结果分析器展示测试结果数据。

基于 LoadRunner 完成企业级性能测试，可以划分为五个阶段：

1. 性能需求收集以及负载计划制定；
   - 系统整体的并发用户数。比如，高峰时段会有 10 万用户同时在线；
   - 并发用户业务操作的分布情况。比如，20% 的用户在做登录操作，30% 的用户在做订单操作，其他 50% 的用户在做搜索操作；
   - 单一业务操作的用户行为模式。比如，两个操作之间的典型停留时间，完成同一业务的不同操作路径等；
   - 并发用户高峰期的时间分布规律。比如，早上 8 点会有大量用户登录系统，晚上 6 点后用户逐渐退出；
   - 达到最高峰负载的时间长度。比如，并发用户从 0 增长到 10 万花费的总时间；…
2. 录制并增强虚拟用户脚本；
3. 创建并定义性能测试场景；
4. 执行性能测试场景；
5. 分析测试报告。

TCPCopy???

### 四类性能测试

### 性能基准测试:Performance Benchmark Test

> 性能基准测试，通常被称为 Performance Benchmark Test，是每次对外发布产品版本前必须要完成的测试类型。

性能基准测试，会基于固定的硬件环境和部署架构（比如专用的服务器、固定的专用网络环境、固定大小的集群规模、相同的系统配置、相同的数据库背景数据等），通过执行固定的性能测试场景得到系统的性能测试报告，然后与上一版本发布时的指标进行对比，如果发现指标有“恶化”的趋势，就需要进一步排查。

典型的“恶化”趋势，主要表现在以下几个方面：

- 同一事务的响应时间变慢了。比如，上一版本中，用户登录的响应时间是 2 s，但是在最新的被测版本中这个响应时间变成了 4 s；
- 系统资源的占用率变高了。比如，上一版本中，平均 CPU 占用率是 15%，但是在最新的被测版本中平均 CPU 占用率变成了 30%；
- 网络带宽的使用量变高了。比如，上一版本中，发送总字节数是 20 MB，接收总字节数是 200 MB，但是在最新的被测版本中发送总字节数变成了 25 MB，接收总字节数变成了 250 MB。

### 稳定性测试

稳定性测试，又称可靠性测试，主要是通过长时间（7*24 小时）模拟被测系统的测试负载，来观察系统在长期运行过程中是否有潜在的问题。通过对系统指标的监控，稳定性测试可以发现诸如内存泄漏、资源非法占用等问题。

一般是采用“波浪式”的测试负载，比如先逐渐加大测试负载，在高负载情况下持续 10 多个小时，然后再逐渐降低负载，这样就构成了一个“波浪”，整个稳定性测试将由很多个这样的波浪连续组成。

稳定性测试成功完成的标志，主要有以下三项：

- 系统资源的所有监控指标不存在“不可逆转”的上升趋势；
- 事务的响应时间不存在逐渐变慢的趋势；
- 事务的错误率不超过 1%。

### 并发测试

并发测试，是在高并发情况下验证单一业务功能的正确性以及性能的测试手段。高并发测试一般使用思考时间为零的虚拟用户脚本来发起具有“集合点”的测试。

### 容量规划测试

容量规划测试，是为了完成容量规划而设计执行的测试。

量规划的主要目的是，解决当系统负载将要达到极限处理能力时，我们应该如何通过垂直扩展（增加单机的硬件资源）和水平扩展（增加集群中的机器数量）增加系统整体的负载处理能力的问题。

目前来讲，容量规划的主要方法是基于水平扩展。但是，具体应该增加多少机器，以及增加后系统的负载处理能力是否会线性增长，这些问题都需要通过容量规划测试进行验证。